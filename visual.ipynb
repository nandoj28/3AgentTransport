{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from random import choice, random\n",
    "import seaborn as sns\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GRID_SIZE = 5\n",
    "ACTIONS = ['north', 'south', 'east', 'west', 'pickup', 'dropoff']\n",
    "AGENT_NAMES = ['red', 'blue', 'black']\n",
    "PICKUP_LOCATIONS = {(1, 5), (2, 4), (5, 2)}\n",
    "DROPOFF_LOCATIONS = {(1, 1), (3, 1), (4, 5)}\n",
    "BLOCKS_INITIAL = 5\n",
    "CAPACITY = 5\n",
    "REWARDS = {'pickup': 13, 'dropoff': 13, 'move': -1}\n",
    "\n",
    "# Initial State Setup\n",
    "def reset_environment():\n",
    "    return {\n",
    "        'positions': {'red': (3, 3), 'blue': (5, 3), 'black': (1, 3)},\n",
    "        'blocks': {(1, 5): 5, (2, 4): 5, (5, 2): 5, (1, 1): 0, (3, 1): 0, (4, 5): 0},\n",
    "        'carrying': {'red': False, 'blue': False, 'black': False}\n",
    "    }\n",
    "\n",
    "# Initialize state\n",
    "state = reset_environment()\n",
    "\n",
    "# Initialize Q-table\n",
    "def initialize_q_table():\n",
    "    q_table = {}\n",
    "    for x in range(1, GRID_SIZE + 1):\n",
    "        for y in range(1, GRID_SIZE + 1):\n",
    "            for carrying in [False, True]:\n",
    "                q_table[((x, y), carrying)] = {a: 0.0 for a in ACTIONS}\n",
    "    return q_table\n",
    "\n",
    "q_table = initialize_q_table()\n",
    "alpha = 0.3\n",
    "gamma = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_action(agent, action, state):\n",
    "    x, y = state['positions'][agent]\n",
    "    if action == 'north' and y > 1:\n",
    "        y -= 1\n",
    "    elif action == 'south' and y < GRID_SIZE:\n",
    "        y += 1\n",
    "    elif action == 'east' and x < GRID_SIZE:\n",
    "        x += 1\n",
    "    elif action == 'west' and x > 1:\n",
    "        x -= 1\n",
    "    elif action == 'pickup' and (x, y) in PICKUP_LOCATIONS and not state['carrying'][agent] and state['blocks'][(x, y)] > 0:\n",
    "        state['carrying'][agent] = True\n",
    "        state['blocks'][(x, y)] -= 1\n",
    "    elif action == 'dropoff' and (x, y) in DROPOFF_LOCATIONS and state['carrying'][agent] and state['blocks'][(x, y)] < CAPACITY:\n",
    "        state['carrying'][agent] = False\n",
    "        state['blocks'][(x, y)] += 1\n",
    "    state['positions'][agent] = (x, y)\n",
    "\n",
    "def select_action(q_table, state, agent, policy):\n",
    "    current_pos = state['positions'][agent]\n",
    "    carrying = state['carrying'][agent]\n",
    "    if policy == 'PRandom':\n",
    "        return choice(list(ACTIONS))\n",
    "    else:\n",
    "        max_action = max(q_table[(current_pos, carrying)], key=q_table[(current_pos, carrying)].get)\n",
    "        if policy == 'PGreedy':\n",
    "            return max_action\n",
    "        elif policy == 'PExploit' and random() < 0.8:\n",
    "            return max_action\n",
    "        else:\n",
    "            return choice(list(ACTIONS))\n",
    "\n",
    "def update_q_table(q_table, state, action, reward, new_state, agent):\n",
    "    old_pos = state['positions'][agent]\n",
    "    new_pos = new_state['positions'][agent]\n",
    "    old_carrying = state['carrying'][agent]\n",
    "    new_carrying = new_state['carrying'][agent]\n",
    "    old_q_value = q_table[(old_pos, old_carrying)][action]\n",
    "    future_q = max(q_table[(new_pos, new_carrying)].values())\n",
    "    q_table[(old_pos, old_carrying)][action] = old_q_value + alpha * (reward + gamma * future_q - old_q_value)\n",
    "\n",
    "def compute_reward(state, action, new_state, agent):\n",
    "    if action == 'pickup' or action == 'dropoff':\n",
    "        return REWARDS[action]\n",
    "    else:\n",
    "        return REWARDS['move']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_q_values(q_table, position, carrying):\n",
    "    actions = ACTIONS\n",
    "    values = [q_table[(position, carrying)][action] for action in actions]\n",
    "    fig, ax = plt.subplots(figsize=(8, 3))\n",
    "    sns.barplot(x=actions, y=values, ax=ax)\n",
    "    ax.set_title(f'Q-values at Position {position} Carrying: {\"Yes\" if carrying else \"No\"}')\n",
    "    ax.set_ylabel('Q-value')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_grid_image(state, cell_size=50):\n",
    "    # Define the size of the image\n",
    "    img_size = GRID_SIZE * cell_size\n",
    "    # Create a white image\n",
    "    grid_img = np.full((img_size, img_size, 3), 255, np.uint8)\n",
    "\n",
    "    # Draw the grid lines\n",
    "    for i in range(GRID_SIZE + 1):\n",
    "        cv2.line(grid_img, (0, i * cell_size), (img_size, i * cell_size), (0, 0, 0), 1)\n",
    "        cv2.line(grid_img, (i * cell_size, 0), (i * cell_size, img_size), (0, 0, 0), 1)\n",
    "\n",
    "    # Add pickup and dropoff locations\n",
    "    for loc in PICKUP_LOCATIONS:\n",
    "        cv2.putText(grid_img, 'P', ((loc[0] - 1) * cell_size + 15, loc[1] * cell_size - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    for loc in DROPOFF_LOCATIONS:\n",
    "        cv2.putText(grid_img, 'D', ((loc[0] - 1) * cell_size + 15, loc[1] * cell_size - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Draw agents\n",
    "    for idx, agent in enumerate(AGENT_NAMES):\n",
    "        pos = state['positions'][agent]\n",
    "        cv2.circle(grid_img, ((pos[0] - 1) * cell_size + cell_size // 2, (pos[1] - 1) * cell_size + cell_size // 2), cell_size // 4, (255, 0, 0), -1)\n",
    "\n",
    "    return grid_img\n",
    "\n",
    "def run_simulation_with_opencv(steps, policy):\n",
    "    state = reset_environment()\n",
    "    for step in range(steps):\n",
    "        if step % 10 == 0:\n",
    "            img = create_grid_image(state)\n",
    "            cv2.imshow('Grid World', img)\n",
    "            cv2.waitKey(100)  # Wait for 100 ms before next update\n",
    "\n",
    "        for agent in AGENT_NAMES:\n",
    "            action = select_action(q_table, state, agent, policy)\n",
    "            apply_action(agent, action, state)\n",
    "            reward = compute_reward(state, action, state, agent)\n",
    "            update_q_table(q_table, state, action, reward, state, agent)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# To run the simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation_with_opencv(1000, 'PRandom')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
